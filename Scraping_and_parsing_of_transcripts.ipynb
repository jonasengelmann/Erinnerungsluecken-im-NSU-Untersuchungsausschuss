{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aL97aiUNThsS"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jonasengelmann/erinnerungsluecken-im-nsu-untersuchungsausschuss/blob/master/Scraping_and_parsing_of_transcripts.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import subprocess\n",
    "import pickle\n",
    "import urllib.request\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PMNiln9mThsX"
   },
   "outputs": [],
   "source": [
    "# Create folder structure:\n",
    "pdf_folder = Path.cwd() / '01_pdfs'\n",
    "Path.mkdir(pdf_folder, exist_ok=True)\n",
    "\n",
    "scarping_result_folder = Path.cwd() / '02_scraping_result'\n",
    "Path.mkdir(scarping_result_folder, exist_ok=True)\n",
    "\n",
    "parsing_result_folder = Path.cwd() / '03_parsing_result'\n",
    "Path.mkdir(parsing_result_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wl7oJGhBqFoj"
   },
   "source": [
    "## 1. Download transcripts as PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W55Y8ZcCqFok"
   },
   "source": [
    "I selected all urls to the transcription files which contain witness interrogations below. You can find all transcription files on the [Bundestag's website](http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SnhaEokTThsb"
   },
   "outputs": [],
   "source": [
    "urls = ['http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2012.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2014.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2015.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2017.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2019.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2021.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2022a.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2022b.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2024a.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2024b.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2027.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2029a.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2029b.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2031.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2032.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2034a.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2034b.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2036.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2039.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2041.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2043.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2044.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2047.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2049a.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2049b.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2051.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2053.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2054.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2056a.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2056b.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2057.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2059a.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2059b.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2060.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2062.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2064a.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2064b.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2065.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2066a.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2066b.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2068a.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2068b.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2070a.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2070b.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2072a.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2072b.pdf',\n",
    "        'http://dipbt.bundestag.de/doc/btd/17/CD14600/Protokolle/Protokoll-Nr%2074.pdf']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qJt_mqFEThsd"
   },
   "outputs": [],
   "source": [
    "# Let's download them:\n",
    "for url in urls:\n",
    "    print(f'Downloading {url}')\n",
    "    urllib.request.urlretrieve(url, pdf_folder / url.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g2oY2jF1qFon"
   },
   "source": [
    "## 2. Scraping with pdfminer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AW-W4-aEqFon"
   },
   "source": [
    "To extract the content of the PDFs as text, we need to scrape them first. There are different scraping tools available, I decided to go with pdfminer, since it has the possibility to preserve most of the layout information by just generating an xml representation of each page. We want to preserve some of the layout information as it hepls us to easier differeniate between speakers, footnotes, quotes and so on. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vcvkc2reThsg"
   },
   "outputs": [],
   "source": [
    "# For python2 use: pip install pdfminer\n",
    "!pip install pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ULiEKB6AThsi"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Scraping all pdfs might take a while, it took me around 10 mins. \n",
    "\n",
    "for filename in list(pdf_folder.glob('*.pdf')):\n",
    "    target = scarping_result_folder / f'{filename.stem}.xml'\n",
    "    print(f'Scraping {filename}')\n",
    "    subprocess.call([\n",
    "        'pdf2txt.py',\n",
    "        '-t',\n",
    "        'xml',\n",
    "        '-n',\n",
    "        '-o',\n",
    "        target,\n",
    "        filename,\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V4fuJJ1NGLXZ"
   },
   "source": [
    "## 3. Parsing XMLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nOcWjuS0Thsl"
   },
   "outputs": [],
   "source": [
    "def crop_vertically(document, crop_percentage):\n",
    "    '''\n",
    "    Removes text elements at the top and bottom of \n",
    "    the document given by percentage of the page size.\n",
    "    '''\n",
    "    crop_document = []\n",
    "    for page in document:\n",
    "        crop_page = []\n",
    "        y1 = float(page.attrib['bbox'].split(',')[3])\n",
    "        for char in page:\n",
    "            if (char.tag == 'text' \n",
    "               and float(char.attrib['bbox'].split(',')[3]) > y1 * crop_percentage\n",
    "               and float(char.attrib['bbox'].split(',')[3]) < y1 * (1 - crop_percentage)):\n",
    "                \n",
    "                crop_page.append(char)\n",
    "        crop_document.append(crop_page)\n",
    "    return crop_document\n",
    "\n",
    "\n",
    "def check_if_characters_match_style(n_characters, font, size):\n",
    "    '''\n",
    "    Checks if all characters match a specified font and\n",
    "    font size. n_characters has to be a list of text elements. \n",
    "    '''\n",
    "    checks = []\n",
    "    for single_char in n_characters:\n",
    "        if (font in single_char.attrib['font'].lower()\n",
    "           and single_char.attrib['size'].startswith(size)):\n",
    "            checks.append(True)\n",
    "        elif single_char.text.strip():\n",
    "            checks.append(True)\n",
    "    return len(checks) == len(n_characters)\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    Removes double space and hyphens resulting from linebreaks.\n",
    "    '''\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return re.sub(r'(\\w)- *(\\w)', '\\\\1\\\\2', text, re.U)\n",
    "  \n",
    "\n",
    "def find_next_speaker_and_text(characters):\n",
    "    '''\n",
    "    Finds the next speaker and text on the basis that speaker are always\n",
    "    written with bold font and in font size 9.\n",
    "    '''\n",
    "    speaker, text = [], []\n",
    "    record_speaker = False\n",
    "    for idx, char in enumerate(characters):\n",
    "\n",
    "        # Check if next 10 characters are bold and in font size 9:\n",
    "        if (check_if_characters_match_style(characters[idx:idx+10], 'bold', '9')\n",
    "            and not record_speaker):\n",
    "\n",
    "            yield ''.join(speaker), clean_text(''.join(text))\n",
    "            \n",
    "            record_speaker = True\n",
    "            speaker = []\n",
    "\n",
    "        if record_speaker:\n",
    "            if char.attrib['size'].strip().startswith('9'):\n",
    "                speaker.append(char.text)\n",
    "        \n",
    "            next_char = characters[idx+1] if (idx+1) != len(characters) else char\n",
    "\n",
    "            # Check if it is the end of the speaker's name:\n",
    "            if not 'bold' in next_char.attrib['font'].lower() and next_char.text.strip():\n",
    "                record_speaker = False\n",
    "                text = []\n",
    "\n",
    "        elif char.attrib['size'].strip().startswith('9'):\n",
    "            text.append(char.text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "protocol = []\n",
    "for filename in sorted(list(scarping_result_folder.glob('*.xml'))):\n",
    "\n",
    "    document = ET.parse(filename).getroot()\n",
    "\n",
    "    # Crop bottom and top by 7 procent to discard of headers and footers\n",
    "    document = crop_vertically(document, crop_percentage=0.07)\n",
    "\n",
    "    # Collect all text characters\n",
    "    text_characters = []\n",
    "    for page in document:\n",
    "        text_characters += [char for char in page if char.tag == 'text']\n",
    "\n",
    "    # Parse content of XMLs\n",
    "    for speaker, text in find_next_speaker_and_text(text_characters):\n",
    "        if speaker.strip():\n",
    "            protocol.append((speaker, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7KCwaXY9Thsn"
   },
   "outputs": [],
   "source": [
    "# Save extracted data:\n",
    "with open(parsing_result_folder / 'parsed_dialog.txt', 'w') as output:\n",
    "    for speaker, text in protocol:\n",
    "        output.write(f'{speaker.strip()} {text.strip()}\\n\\n')\n",
    "\n",
    "pickle.dump(protocol, open(parsing_result_folder / 'parsed_dialog.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eAV8m5ilThsp"
   },
   "outputs": [],
   "source": [
    "# In Colab you can download the parsed_dialog file like this:\n",
    "from google.colab import files\n",
    "files.download(parsing_result_folder / 'parsed_dialog.txt')"
   ]
  }
 ],
"metadata": {
   "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },  
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
